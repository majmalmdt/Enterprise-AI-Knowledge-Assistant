# ğŸ§  Enterprise AI Knowledge Assistant (RAG System)

An event-driven, real-time AI Knowledge Assistant built using FastAPI, Retrieval-Augmented Generation (RAG), ChromaDB, Redis Pub/Sub, and WebSockets. This project demonstrates production-grade AI system design, not just prompt engineering.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![Redis](https://img.shields.io/badge/Redis-7.0+-red.svg)

---

## ğŸš€ Features

- ğŸ“„ **Document ingestion & vectorization** - Upload and process documents into semantic chunks
- ğŸ§  **Semantic search using ChromaDB** - Vector similarity search for intelligent retrieval
- ğŸ¤– **LLM-powered question answering (RAG)** - Context-aware responses using retrieved knowledge
- ğŸ”„ **Event-driven architecture with Redis** - Decoupled, scalable message routing
- ğŸ’¬ **Real-time chat via WebSockets** - Bidirectional streaming communication
- ğŸ§© **Modular, scalable project structure** - Clean architecture for enterprise deployments
- ğŸ›¡ï¸ **Hallucination-safe responses** - Returns "I don't know" when context is missing

---

## ğŸ—ï¸ Architecture Overview

```
Client (Postman / Browser)
        â”‚
        â–¼
 WebSocket (FastAPI)
        â”‚
        â–¼
 Redis Pub/Sub (event bus)
        â”‚
        â–¼
 RAG Service
   â”œâ”€ ChromaDB (vector search)
   â”œâ”€ Embedding Model
   â””â”€ LLM Service
        â”‚
        â–¼
 WebSocket Response (Real-time)
```

---

## ğŸ“‚ Project Structure

```
app/
â”œâ”€â”€ main.py                      # FastAPI application entry point
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ chat.py              # WebSocket chat endpoint
â”‚       â”œâ”€â”€ documents.py         # Document upload/management
â”‚       â””â”€â”€ section.py           # Document section CRUD
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ rag_service.py           # RAG orchestration logic
â”‚   â”œâ”€â”€ embedding_service.py     # Text embedding generation
â”‚   â”œâ”€â”€ llm_service.py           # LLM integration (OpenAI/Azure)
â”‚   â””â”€â”€ websocket_manager.py    # WebSocket connection management
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ chroma_client.py         # ChromaDB client wrapper
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ producer.py              # Redis publisher for events
â”œâ”€â”€ db/
â”‚   â””â”€â”€ base.py                  # SQLAlchemy base models
â”œâ”€â”€ models/
â”‚   â””â”€â”€ section.py               # Document section schema
â””â”€â”€ database.py                  # Database connection setup
```

---

## ğŸ”§ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Backend** | FastAPI (async) |
| **Real-time Messaging** | WebSockets |
| **Event Streaming** | Redis Pub/Sub |
| **Vector Database** | ChromaDB |
| **LLM** | OpenAI / Azure OpenAI (pluggable) |
| **Embeddings** | Transformer-based embeddings |
| **Database** | PostgreSQL (SQLAlchemy) |
| **Language** | Python 3.10+ |

---

## ğŸ§  RAG Pipeline (How it Works)

1. **Documents are uploaded** and parsed
2. **Text is chunked** into semantic units
3. **Chunks are converted** into embeddings
4. **Embeddings are stored** in ChromaDB
5. **User queries are embedded**
6. **Top-K similar chunks** are retrieved
7. **Retrieved context** is sent to the LLM
8. **Final answer** is streamed back via WebSocket

---

## âš¡ Real-Time Chat Flow

1. Client connects via WebSocket
2. Messages are published to Redis
3. RAG service processes messages
4. Responses are published back to Redis
5. WebSocket streams response to client

**This design supports multiple clients and workers.**

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10+
- Redis Server
- PostgreSQL
- OpenAI API Key (or Azure OpenAI)

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/enterprise-rag-system.git
cd enterprise-rag-system

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your configuration
```

### Environment Variables

```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/rag_db

# Redis
REDIS_URL=redis://localhost:6379

# OpenAI
OPENAI_API_KEY=your_api_key_here
MODEL_NAME=gpt-4

# ChromaDB
CHROMA_DB_DIR=./chroma_db

```

---

## ğŸš€ Running the Application

### 1ï¸âƒ£ Start Redis

```bash
redis-server
```

### 2ï¸âƒ£ Start PostgreSQL

```bash
# Using Docker
docker run --name postgres-rag -e POSTGRES_PASSWORD=password -p 5432:5432 -d postgres

# Or use your local PostgreSQL installation
```

### 3ï¸âƒ£ Run Database Migrations

```bash
alembic upgrade head
```

### 4ï¸âƒ£ Start the Application

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

---

## ğŸ§ª Testing (No Manual UI)

### Using Postman

#### 1. Upload a Document

```http
POST http://localhost:8000/api/documents/{section_id}
Content-Type: multipart/form-data

file: [your_document.pdf]
```

#### 2. Connect to WebSocket

```
ws://127.0.0.1:8000/ws/chat/{section_id}
```

Send message:
```json
{
  "message": "What is FastAPI?"
}
```


## ğŸ§ª Debugging & Observability

The system includes detailed logs for:

- âœ… WebSocket connections
- âœ… Redis pub/sub events
- âœ… RAG retrieval results
- âœ… LLM responses


## ğŸ“Œ Why This Project Matters

This project demonstrates:

- âœ… Real-world AI system design
- âœ… Event-driven architectures
- âœ… Async backend expertise
- âœ… Vector search + LLM integration
- âœ… Production-style safety guardrails

**It is not a toy chatbot, but a scalable AI platform foundation.**

---

## ğŸ“„ API Documentation

Once running, access the interactive API docs:

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

---


## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) file for details

---

## ğŸ‘¥ Authors

- **Muhammed Ajmal** - [GitHub](https://github.com/majmalmdt)

---

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- ChromaDB team for vector database
- FastAPI community
- Redis labs

---


**â­ If you find this project useful, please consider giving it a star!**